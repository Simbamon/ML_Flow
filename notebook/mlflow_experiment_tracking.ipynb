{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import mlflow\n",
    "import pandas as pd\n",
    "# import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.datasets import fetch_california_housing\n",
    "import tensorflow_addons as tfa\n",
    "\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "\n",
    "from tabtransformertf.models.fttransformer import FTTransformerEncoder, FTTransformer\n",
    "from tabtransformertf.utils.preprocessing import df_to_dataset\n",
    "\n",
    "import catboost as cb\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "import seaborn as sns\n",
    "\n",
    "from tensorflow.keras.layers import Dense, Dropout\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.losses import MeanSquaredError"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "12e4647c",
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "plt.rcParams[\"figure.figsize\"] = (20,10)\n",
    "plt.rcParams.update({'font.size': 15})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3fd78161",
   "metadata": {},
   "outputs": [],
   "source": [
    "mlflow.set_tracking_uri(\"sqlite:///mlflow.db\")\n",
    "mlflow.set_experiment(\"income\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70578a3e",
   "metadata": {},
   "source": [
    "## Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e16a2775",
   "metadata": {},
   "outputs": [],
   "source": [
    "dset = fetch_california_housing()\n",
    "data = dset['data']\n",
    "y = dset['target']\n",
    "LABEL = dset['target_names'][0]\n",
    "\n",
    "NUMERIC_FEATURES = ['MedInc', 'HouseAge', 'AveRooms', 'AveBedrms', 'Population', 'AveOccup', 'Longitude', 'Latitude']\n",
    "FEATURES = NUMERIC_FEATURES\n",
    "\n",
    "data = pd.DataFrame(data, columns=dset['feature_names'])\n",
    "data[LABEL] = y\n",
    "\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a43a381",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data, test_data = train_test_split(data, test_size=0.2)\n",
    "print(f\"Train dataset shape: {train_data.shape}\")\n",
    "print(f\"Test dataset shape: {test_data.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "768867d8",
   "metadata": {},
   "source": [
    "## Data Processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "6732f032",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_val = train_test_split(train_data, test_size=0.2)\n",
    "\n",
    "sc = StandardScaler()\n",
    "X_train.loc[:, NUMERIC_FEATURES] = sc.fit_transform(X_train[NUMERIC_FEATURES])\n",
    "X_val.loc[:, NUMERIC_FEATURES] = sc.transform(X_val[NUMERIC_FEATURES])\n",
    "test_data.loc[:, NUMERIC_FEATURES] = sc.transform(test_data[NUMERIC_FEATURES])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "edb799fb",
   "metadata": {},
   "source": [
    "## Baseline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "e7a73f63",
   "metadata": {},
   "outputs": [],
   "source": [
    "mlflow.sklearn.autolog(disable=True)\n",
    "\n",
    "with mlflow.start_run(run_name='rf_baseline'):\n",
    "    params = {\n",
    "        \"n_estimators\": 100,\n",
    "        \"max_depth\": 20\n",
    "    }\n",
    "\n",
    "    mlflow.set_tag(\"model_name\", \"RF\")\n",
    "    mlflow.log_params(params)\n",
    "\n",
    "    rf = RandomForestRegressor(n_estimators=100, max_depth=20)\n",
    "    rf.fit(X_train[FEATURES], X_train[LABEL])\n",
    "\n",
    "    rf_preds = rf.predict(test_data[FEATURES])\n",
    "    rf_rms = mean_squared_error(test_data[LABEL], rf_preds, squared=False)\n",
    "\n",
    "    mlflow.log_metric(\"test_rmse\", rf_rms)\n",
    "    mlflow.sklearn.log_model(rf, \"sk_models\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f1bb7201",
   "metadata": {},
   "source": [
    "## CatBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "056dbf4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "catb_train_dataset = cb.Pool(X_train[FEATURES], X_train[LABEL]) \n",
    "catb_val_dataset = cb.Pool(X_val[FEATURES], X_val[LABEL]) \n",
    "catb_test_dataset = cb.Pool(test_data[FEATURES], test_data[LABEL])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0355894e",
   "metadata": {},
   "outputs": [],
   "source": [
    "with mlflow.start_run(run_name=\"catboost\"):\n",
    "    mlflow.set_tag(\"model_name\", \"CatBoost\")\n",
    "    catb = cb.CatBoostRegressor()\n",
    "    catb.fit(catb_train_dataset, eval_set=catb_val_dataset, early_stopping_rounds=50)\n",
    "    catb_preds = catb.predict(catb_test_dataset)\n",
    "    catb_rms = mean_squared_error(test_data[LABEL], catb_preds, squared=False)\n",
    "\n",
    "    mlflow.log_metric(\"test_rmse\", catb_rms)\n",
    "    mlflow.catboost.log_model(catb, \"cb_models\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "03687c96",
   "metadata": {},
   "source": [
    "## MLP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "id": "8cfc937e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_mlp(params):\n",
    "    mlp = Sequential([\n",
    "        Dense(params[\"layer1_size\"], activation=params['activation']),\n",
    "        Dropout(params['dropout_rate']),\n",
    "        Dense(params[\"layer2_size\"], activation=params['activation']),\n",
    "        Dropout(params['dropout_rate']),\n",
    "        Dense(params[\"layer3_size\"], activation=params['activation']),\n",
    "        Dense(1, activation='relu')\n",
    "    ])\n",
    "    return mlp\n",
    "\n",
    "def train_mlp(mlp, train_params, train_dataset, val_dataset):\n",
    "    optimizer = tfa.optimizers.AdamW(\n",
    "        learning_rate=train_params[\"learning_rate\"],\n",
    "        weight_decay=train_params[\"weight_decay\"],\n",
    "    )\n",
    "    mlp.compile(\n",
    "        optimizer=optimizer,\n",
    "        loss=MeanSquaredError(name=\"mse\"),\n",
    "        metrics=[tf.keras.metrics.RootMeanSquaredError(name=\"rmse\")]\n",
    "    )\n",
    "\n",
    "    early = EarlyStopping(\n",
    "        monitor=\"val_loss\",\n",
    "        mode=\"min\",\n",
    "        patience=train_params[\"early_stop_patience\"],\n",
    "        restore_best_weights=True,\n",
    "    )\n",
    "    callback_list = [early]\n",
    "\n",
    "    hist = mlp.fit(\n",
    "        train_dataset,\n",
    "        epochs=train_params[\"num_epochs\"],\n",
    "        validation_data=val_dataset,\n",
    "        callbacks=callback_list,\n",
    "    )\n",
    "    return mlp\n",
    "\n",
    "\n",
    "def mlp_mlflow_run(\n",
    "    name,\n",
    "    mlp_params,\n",
    "    train_params,\n",
    "    train_dataset,\n",
    "    val_dataset,\n",
    "    test_dataset,\n",
    "    y_test,\n",
    "):\n",
    "    with mlflow.start_run(run_name=name):\n",
    "        mlflow.log_params(mlp_params)\n",
    "        mlflow.log_params(train_params)\n",
    "        mlflow.set_tag(\"model_name\", \"MLP\")\n",
    "        mlp = build_mlp(mlp_params)\n",
    "        mlp = train_mlp(mlp, train_params, train_dataset, val_dataset)\n",
    "        test_preds = mlp.predict(test_dataset)\n",
    "        test_rms = mean_squared_error(\n",
    "            y_test, test_preds.ravel(), squared=False\n",
    "        )\n",
    "        mlflow.log_metric(\"test_rmse\", test_rms)\n",
    "        mlflow.tensorflow.log_model(mlp, \"tf_models\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14b89274",
   "metadata": {},
   "outputs": [],
   "source": [
    "# To TF Dataset\n",
    "mlp_train_ds = tf.data.Dataset.from_tensor_slices((X_train[FEATURES], X_train[LABEL])).batch(512).shuffle(512*4).prefetch(512)\n",
    "mlp_val_ds = tf.data.Dataset.from_tensor_slices((X_val[FEATURES], X_val[LABEL])).batch(512).shuffle(512*4).prefetch(512)\n",
    "mlp_test_ds = tf.data.Dataset.from_tensor_slices(test_data[FEATURES]).batch(512).prefetch(512)\n",
    "\n",
    "mlp_params = {\n",
    "    \"layer1_size\": 512,\n",
    "    \"layer2_size\": 128,\n",
    "    \"layer3_size\": 64,\n",
    "    \"dropout_rate\": 0.3,\n",
    "    \"activation\": 'relu'\n",
    "\n",
    "}\n",
    "train_params = dict(\n",
    "    learning_rate=0.001, weight_decay=0.00001, early_stop_patience=10, num_epochs=1000\n",
    ")\n",
    "\n",
    "mlp_mlflow_run(\n",
    "    \"mlp_base\",\n",
    "    mlp_params,\n",
    "    train_params,\n",
    "    mlp_train_ds,\n",
    "    mlp_val_ds,\n",
    "    mlp_test_ds,\n",
    "    test_data[LABEL],\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f78bfdc9",
   "metadata": {},
   "outputs": [],
   "source": [
    "mlp_mlflow_run"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc0c081d",
   "metadata": {},
   "source": [
    "## FT Transformers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d91e1468",
   "metadata": {},
   "outputs": [],
   "source": [
    "# To TF Dataset\n",
    "train_dataset = df_to_dataset(X_train[FEATURES + [LABEL]], LABEL, shuffle=True)\n",
    "val_dataset = df_to_dataset(X_val[FEATURES + [LABEL]], LABEL, shuffle=False)  # No shuffle\n",
    "test_dataset = df_to_dataset(test_data[FEATURES], shuffle=False) # No target, no shuffle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "c9766fd0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_fttransformer(\n",
    "    params_to_log, params_to_skip, out_dim=1, out_activation=\"relu\"\n",
    "):\n",
    "    # Define encoder\n",
    "    ft_encoder = FTTransformerEncoder(\n",
    "        **params_to_log,\n",
    "        **params_to_skip\n",
    "    )\n",
    "    # Add prediction head to the encoder\n",
    "    ft_transformer = FTTransformer(\n",
    "        encoder=ft_encoder,\n",
    "        out_dim=out_dim,\n",
    "        out_activation=out_activation,\n",
    "    )\n",
    "\n",
    "    return ft_transformer\n",
    "\n",
    "\n",
    "def train_model(model, train_params, train_dataset, val_dataset):\n",
    "    optimizer = tfa.optimizers.AdamW(\n",
    "        learning_rate=train_params[\"learning_rate\"],\n",
    "        weight_decay=train_params[\"weight_decay\"],\n",
    "    )\n",
    "\n",
    "    model.compile(\n",
    "        optimizer=optimizer,\n",
    "        loss={\n",
    "            \"output\": tf.keras.losses.MeanSquaredError(name=\"mse\"),\n",
    "            \"importances\": None,\n",
    "        },\n",
    "        metrics={\n",
    "            \"output\": [tf.keras.metrics.RootMeanSquaredError(name=\"rmse\")],\n",
    "            \"importances\": None,\n",
    "        },\n",
    "    )\n",
    "\n",
    "    early = EarlyStopping(\n",
    "        monitor=\"val_output_loss\",\n",
    "        mode=\"min\",\n",
    "        patience=train_params[\"early_stop_patience\"],\n",
    "        restore_best_weights=True,\n",
    "    )\n",
    "    callback_list = [early]\n",
    "\n",
    "    hist = model.fit(\n",
    "        train_dataset,\n",
    "        epochs=train_params[\"num_epochs\"],\n",
    "        validation_data=val_dataset,\n",
    "        callbacks=callback_list,\n",
    "    )\n",
    "    return model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "7b38b852",
   "metadata": {},
   "outputs": [],
   "source": [
    "mlflow.tensorflow.autolog(disable=True)\n",
    "\n",
    "\n",
    "def fttransformer_mlflow_run(\n",
    "    name,\n",
    "    encoder_params,\n",
    "    train_params,\n",
    "    params_to_skip,\n",
    "    train_dataset,\n",
    "    val_dataset,\n",
    "    test_dataset,\n",
    "    y_test,\n",
    "):\n",
    "    with mlflow.start_run(run_name=name):\n",
    "        mlflow.set_tag(\"model_name\", \"FTTransformer\")\n",
    "        # Log the params\n",
    "        mlflow.log_params(encoder_params)\n",
    "        mlflow.log_params(train_params)\n",
    "        # Build and train\n",
    "        ft_transformer = build_fttransformer(\n",
    "            encoder_params,\n",
    "            params_to_skip,\n",
    "            out_dim=1,\n",
    "            out_activation=\"relu\",\n",
    "        )\n",
    "        ft_transformer = train_model(\n",
    "            ft_transformer, train_params, train_dataset, val_dataset\n",
    "        )\n",
    "        # Evaluate\n",
    "        test_preds = ft_transformer.predict(test_dataset)\n",
    "        test_rms = mean_squared_error(\n",
    "            y_test, test_preds[\"output\"].ravel(), squared=False\n",
    "        )\n",
    "        mlflow.log_metric(\"test_rmse\", test_rms)\n",
    "        mlflow.tensorflow.log_model(ft_transformer, \"tf_models\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "5680ace8",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_params = dict(\n",
    "    learning_rate=0.001, weight_decay=0.00001, early_stop_patience=10, num_epochs=1000\n",
    ")\n",
    "\n",
    "params_to_skip = dict(\n",
    "    numerical_data=X_train[NUMERIC_FEATURES].values,\n",
    "    categorical_data=None,\n",
    "    y=X_train[LABEL].values\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9e979ac",
   "metadata": {},
   "source": [
    "### Linear Embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9247cf48",
   "metadata": {},
   "outputs": [],
   "source": [
    "linear_embeddings_params = dict(\n",
    "    numerical_features=NUMERIC_FEATURES,\n",
    "    categorical_features=[],\n",
    "    numerical_embedding_type=\"linear\",\n",
    "    embedding_dim=64,\n",
    "    depth=3,\n",
    "    heads=6,\n",
    "    attn_dropout=0.3,\n",
    "    ff_dropout=0.3,\n",
    "    explainable=True,\n",
    ")\n",
    "\n",
    "fttransformer_mlflow_run(\n",
    "    name='linear',\n",
    "    encoder_params=linear_embeddings_params,\n",
    "    train_params=train_params,\n",
    "    params_to_skip=params_to_skip,\n",
    "    train_dataset=train_dataset,\n",
    "    val_dataset=val_dataset,\n",
    "    test_dataset=test_dataset,\n",
    "    y_test=test_data[LABEL],\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af43cb7a",
   "metadata": {},
   "source": [
    "### Periodic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab954586",
   "metadata": {},
   "outputs": [],
   "source": [
    "periodic_params_to_log = dict(\n",
    "    numerical_features=NUMERIC_FEATURES,\n",
    "    categorical_features=[],\n",
    "    numerical_embedding_type='periodic',\n",
    "    numerical_bins=128,\n",
    "    embedding_dim=64,\n",
    "    depth=3,\n",
    "    heads=6,\n",
    "    attn_dropout=0.3,\n",
    "    ff_dropout=0.3,\n",
    "    explainable=True,\n",
    ")\n",
    "\n",
    "fttransformer_mlflow_run(\n",
    "    name='periodic',\n",
    "    encoder_params=periodic_params_to_log,\n",
    "    train_params=train_params,\n",
    "    params_to_skip=params_to_skip,\n",
    "    train_dataset=train_dataset,\n",
    "    val_dataset=val_dataset,\n",
    "    test_dataset=test_dataset,\n",
    "    y_test=test_data[LABEL],\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9804404f",
   "metadata": {},
   "source": [
    "### PLE - Quantile Binning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99796911",
   "metadata": {},
   "outputs": [],
   "source": [
    "pleq_params_to_log = dict(\n",
    "    numerical_features=NUMERIC_FEATURES,\n",
    "    categorical_features=[],\n",
    "    numerical_embedding_type='ple',\n",
    "    numerical_bins=128,\n",
    "    embedding_dim=64,\n",
    "    depth=3,\n",
    "    heads=6,\n",
    "    attn_dropout=0.3,\n",
    "    ff_dropout=0.3,\n",
    "    explainable=True,\n",
    ")\n",
    "\n",
    "pleq_params_to_skip = params_to_skip.copy()\n",
    "pleq_params_to_skip['y'] = None\n",
    "\n",
    "fttransformer_mlflow_run(\n",
    "    name='ple_quantile',\n",
    "    encoder_params=pleq_params_to_log,\n",
    "    train_params=train_params,\n",
    "    params_to_skip=pleq_params_to_skip,\n",
    "    train_dataset=train_dataset,\n",
    "    val_dataset=val_dataset,\n",
    "    test_dataset=test_dataset,\n",
    "    y_test=test_data[LABEL],\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df9b6b4c",
   "metadata": {},
   "source": [
    "### PLE - Target Binning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c6fd366",
   "metadata": {},
   "outputs": [],
   "source": [
    "plet_params_to_log = dict(\n",
    "    numerical_features=NUMERIC_FEATURES,\n",
    "    categorical_features=[],\n",
    "    numerical_embedding_type='ple',\n",
    "    numerical_bins=128,\n",
    "    embedding_dim=64,\n",
    "    depth=3,\n",
    "    heads=6,\n",
    "    attn_dropout=0.3,\n",
    "    ff_dropout=0.3,\n",
    "    explainable=True,\n",
    "    task='regression',\n",
    "    ple_tree_params = {\n",
    "        \"min_samples_leaf\": 20,\n",
    "    }\n",
    ")\n",
    "\n",
    "\n",
    "fttransformer_mlflow_run(\n",
    "    name='ple_target',\n",
    "    encoder_params=plet_params_to_log,\n",
    "    train_params=train_params,\n",
    "    params_to_skip=params_to_skip,\n",
    "    train_dataset=train_dataset,\n",
    "    val_dataset=val_dataset,\n",
    "    test_dataset=test_dataset,\n",
    "    y_test=test_data[LABEL],\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "c32fee20",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_id = \"\" # take it from mlflow\n",
    "loaded_ft = mlflow.tensorflow.load_model(model_id)"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "a2df742b932880654a3f6652148a9c802dc0dfad475f6beda4797814052023f2"
  },
  "kernelspec": {
   "display_name": "Python 3.9.13",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
